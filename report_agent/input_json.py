"""
åˆ›å»ºReport Agentè¾“å…¥JSONæ–‡ä»¶

å°†ä¼˜åŒ–å› å­å’ŒæŠ•èµ„ç»„åˆä¼˜åŒ–æŠ¥å‘Šçš„é‡è¦æ•°æ®åˆå¹¶æˆä¸€ä¸ªJSONæ–‡ä»¶ï¼Œ
ä½œä¸ºreport agentçš„è¾“å…¥æ•°æ®ã€‚
"""

import json
import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List


def load_factor_stats(file_path: str) -> Dict[str, Any]:
    """åŠ è½½å› å­ç»Ÿè®¡ä¿¡æ¯"""
    try:
        df = pd.read_csv(file_path)
        stats = {}
        for _, row in df.iterrows():
            factor_name = row['factor_name']
            stats[factor_name] = {
                'count': int(row['count']),
                'mean': float(row['mean']),
                'std': float(row['std']),
                'min': float(row['min']),
                'max': float(row['max']),
                'range': float(row['max']) - float(row['min']),
                'cv': float(row['std']) / abs(float(row['mean'])) if abs(float(row['mean'])) > 1e-10 else float('inf')
            }
        return stats
    except Exception as e:
        print(f"Error loading factor stats from {file_path}: {e}")
        return {}


def load_portfolio_summary(file_path: str) -> Dict[str, Any]:
    """åŠ è½½æŠ•èµ„ç»„åˆä¼˜åŒ–æ‘˜è¦"""
    try:
        df = pd.read_csv(file_path)
        summary = {}
        for _, row in df.iterrows():
            market = row['market']
            method = row['method']
            if market not in summary:
                summary[market] = {}
            summary[market][method] = {
                'expected_return': float(row['expected_return']),
                'volatility': float(row['volatility']),
                'sharpe_ratio': float(row['sharpe_ratio']),
                'factor_count': int(row['factor_count'])
            }
        return summary
    except Exception as e:
        print(f"Error loading portfolio summary from {file_path}: {e}")
        return {}


def load_portfolio_weights(file_path: str) -> Dict[str, Any]:
    """åŠ è½½æŠ•èµ„ç»„åˆæƒé‡"""
    try:
        df = pd.read_csv(file_path)
        weights = {}
        for _, row in df.iterrows():
            method = row['method']
            factor = row['factor']
            weight = float(row['weight'])
            
            if method not in weights:
                weights[method] = {}
            weights[method][factor] = {
                'weight': weight,
                'expected_return': float(row['expected_return']),
                'volatility': float(row['volatility']),
                'sharpe_ratio': float(row['sharpe_ratio'])
            }
        return weights
    except Exception as e:
        print(f"Error loading portfolio weights from {file_path}: {e}")
        return {}


def analyze_factor_quality(factor_stats: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ†æå› å­è´¨é‡"""
    quality_metrics = {}
    
    for factor_name, stats in factor_stats.items():
        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        stability_score = 1.0 / (1.0 + stats['cv']) if stats['cv'] != float('inf') else 0.0
        range_score = min(1.0, 10.0 / stats['range']) if stats['range'] > 0 else 0.0
        distribution_score = 1.0 - abs(stats['mean']) / stats['std'] if stats['std'] > 0 else 0.0
        
        quality_metrics[factor_name] = {
            'stability_score': stability_score,
            'range_score': range_score,
            'distribution_score': distribution_score,
            'overall_quality': (stability_score + range_score + distribution_score) / 3.0,
            'is_outlier_prone': stats['cv'] > 2.0,
            'is_extreme_range': stats['range'] > 10.0
        }
    
    return quality_metrics


def analyze_portfolio_performance(portfolio_summary: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ†ææŠ•èµ„ç»„åˆè¡¨ç°"""
    performance_analysis = {}
    
    for market, methods in portfolio_summary.items():
        market_analysis = {
            'best_sharpe_method': None,
            'best_return_method': None,
            'lowest_risk_method': None,
            'method_comparison': {}
        }
        
        best_sharpe = -float('inf')
        best_return = -float('inf')
        lowest_risk = float('inf')
        
        for method, metrics in methods.items():
            # è®°å½•æœ€ä½³æ–¹æ³•
            if metrics['sharpe_ratio'] > best_sharpe:
                best_sharpe = metrics['sharpe_ratio']
                market_analysis['best_sharpe_method'] = method
            
            if metrics['expected_return'] > best_return:
                best_return = metrics['expected_return']
                market_analysis['best_return_method'] = method
            
            if metrics['volatility'] < lowest_risk:
                lowest_risk = metrics['volatility']
                market_analysis['lowest_risk_method'] = method
            
            # æ–¹æ³•æ¯”è¾ƒ
            market_analysis['method_comparison'][method] = {
                'risk_return_ratio': metrics['expected_return'] / metrics['volatility'] if metrics['volatility'] > 0 else 0,
                'risk_adjusted_return': metrics['expected_return'] - 0.5 * metrics['volatility'],
                'volatility_rank': 0,  # å°†åœ¨åç»­è®¡ç®—
                'return_rank': 0,      # å°†åœ¨åç»­è®¡ç®—
                'sharpe_rank': 0       # å°†åœ¨åç»­è®¡ç®—
            }
        
        # è®¡ç®—æ’å
        volatility_values = [m['volatility'] for m in methods.values()]
        return_values = [m['expected_return'] for m in methods.values()]
        sharpe_values = [m['sharpe_ratio'] for m in methods.values()]
        
        for method, metrics in methods.items():
            market_analysis['method_comparison'][method]['volatility_rank'] = sorted(volatility_values).index(metrics['volatility']) + 1
            market_analysis['method_comparison'][method]['return_rank'] = sorted(return_values, reverse=True).index(metrics['expected_return']) + 1
            market_analysis['method_comparison'][method]['sharpe_rank'] = sorted(sharpe_values, reverse=True).index(metrics['sharpe_ratio']) + 1
        
        performance_analysis[market] = market_analysis
    
    return performance_analysis


def create_comprehensive_json():
    """åˆ›å»ºç»¼åˆçš„JSONè¾“å…¥æ–‡ä»¶"""
    
    # æ•°æ®æ–‡ä»¶è·¯å¾„
    base_path = Path("portfolios")
    
    # åŠ è½½æ‰€æœ‰æ•°æ®
    print("Loading factor statistics...")
    a_share_stats = load_factor_stats(base_path / "optimized_factors" / "a_share_optimized_factors_stats.csv")
    crypto_stats = load_factor_stats(base_path / "optimized_factors" / "crypto_optimized_factors_stats.csv")
    us_stats = load_factor_stats(base_path / "optimized_factors" / "us_optimized_factors_stats.csv")
    
    print("Loading portfolio summary...")
    portfolio_summary = load_portfolio_summary(base_path / "optimization_reports" / "portfolio_optimization_summary.csv")
    
    print("Loading portfolio weights...")
    a_share_weights = load_portfolio_weights(base_path / "optimization_reports" / "a_share_portfolio_weights.csv")
    crypto_weights = load_portfolio_weights(base_path / "optimization_reports" / "crypto_portfolio_weights.csv")
    us_weights = load_portfolio_weights(base_path / "optimization_reports" / "us_portfolio_weights.csv")
    
    # åˆ†æå› å­è´¨é‡
    print("Analyzing factor quality...")
    a_share_quality = analyze_factor_quality(a_share_stats)
    crypto_quality = analyze_factor_quality(crypto_stats)
    us_quality = analyze_factor_quality(us_stats)
    
    # åˆ†ææŠ•èµ„ç»„åˆè¡¨ç°
    print("Analyzing portfolio performance...")
    performance_analysis = analyze_portfolio_performance(portfolio_summary)
    
    # åˆ›å»ºç»¼åˆJSONç»“æ„
    comprehensive_data = {
        "metadata": {
            "generated_at": datetime.now().isoformat(),
            "data_source": "portfolios/optimized_factors and portfolios/optimization_reports",
            "total_markets": 3,
            "total_factors": len(a_share_stats) + len(crypto_stats) + len(us_stats),
            "optimization_methods": ["max_sharpe", "min_volatility", "efficient_return", "hrp", "cla"]
        },
        
        "factor_analysis": {
            "a_share": {
                "factor_statistics": a_share_stats,
                "factor_quality": a_share_quality,
                "selected_factors": list(a_share_stats.keys()),
                "total_factors": len(a_share_stats),
                "high_quality_factors": [f for f, q in a_share_quality.items() if q['overall_quality'] > 0.7],
                "problematic_factors": [f for f, q in a_share_quality.items() if q['is_outlier_prone'] or q['is_extreme_range']]
            },
            "crypto": {
                "factor_statistics": crypto_stats,
                "factor_quality": crypto_quality,
                "selected_factors": list(crypto_stats.keys()),
                "total_factors": len(crypto_stats),
                "high_quality_factors": [f for f, q in crypto_quality.items() if q['overall_quality'] > 0.7],
                "problematic_factors": [f for f, q in crypto_quality.items() if q['is_outlier_prone'] or q['is_extreme_range']]
            },
            "us": {
                "factor_statistics": us_stats,
                "factor_quality": us_quality,
                "selected_factors": list(us_stats.keys()),
                "total_factors": len(us_stats),
                "high_quality_factors": [f for f, q in us_quality.items() if q['overall_quality'] > 0.7],
                "problematic_factors": [f for f, q in us_quality.items() if q['is_outlier_prone'] or q['is_extreme_range']]
            }
        },
        
        "portfolio_optimization": {
            "summary": portfolio_summary,
            "performance_analysis": performance_analysis,
            "weights": {
                "a_share": a_share_weights,
                "crypto": crypto_weights,
                "us": us_weights
            }
        },
        
        "optimization_methods": {
            "max_sharpe": {
                "description": "æœ€å¤§åŒ–å¤æ™®æ¯”ç‡ç»„åˆ",
                "objective": "åœ¨ç»™å®šé£é™©æ°´å¹³ä¸‹æœ€å¤§åŒ–é¢„æœŸæ”¶ç›Š",
                "risk_level": "ä¸­ç­‰"
            },
            "min_volatility": {
                "description": "æœ€å°æ³¢åŠ¨ç‡ç»„åˆ",
                "objective": "æœ€å°åŒ–æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡",
                "risk_level": "ä½"
            },
            "efficient_return": {
                "description": "é«˜æ•ˆæ”¶ç›Šç»„åˆ",
                "objective": "åœ¨ç»™å®šæ”¶ç›Šç›®æ ‡ä¸‹æœ€å°åŒ–é£é™©",
                "risk_level": "ä¸­ç­‰"
            },
            "hrp": {
                "description": "åˆ†å±‚é£é™©å¹³ä»·ç»„åˆ",
                "objective": "åŸºäºèµ„äº§ç›¸å…³æ€§è¿›è¡Œé£é™©åˆ†é…",
                "risk_level": "ä½"
            },
            "cla": {
                "description": "ä¸´ç•Œçº¿ç®—æ³•ç»„åˆ",
                "objective": "åŸºäºå‡å€¼æ–¹å·®ç†è®ºçš„æœ€ä¼˜ç»„åˆ",
                "risk_level": "ä¸­ç­‰"
            }
        },
        
        "factor_generation_methods": {
            "Alpha-GFN": {
                "description": "åŸºäºGFlowNetçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ å› å­æŒ–æ˜",
                "factors": ["GFN_Momentum", "GFN_LogPrice", "GFN_Volatility", "GFN_Composite"],
                "methodology": "ä½¿ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¢ç´¢å› å­ç©ºé—´"
            },
            "AlphaAgent": {
                "description": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
                "factors": ["Agent_MACD", "Agent_MomentumReversal"],
                "methodology": "LLMé©±åŠ¨çš„å¤šæ™ºèƒ½ä½“åä½œå› å­ç”Ÿæˆ"
            },
            "AlphaGen": {
                "description": "åŸºäºPPOçš„å› å­ç”Ÿæˆ",
                "factors": ["Gen_VolumeAnomaly", "Gen_PriceAcceleration"],
                "methodology": "è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ç®—æ³•ç”Ÿæˆå› å­"
            },
            "AlphaMiner": {
                "description": "ä¼ ç»ŸæŠ€æœ¯æŒ‡æ ‡æŒ–æ˜",
                "factors": ["Miner_SMACross"],
                "methodology": "åŸºäºä¼ ç»ŸæŠ€æœ¯åˆ†ææŒ‡æ ‡"
            },
            "Genetic-Alpha": {
                "description": "é—ä¼ ç¼–ç¨‹ç¬¦å·å›å½’",
                "factors": ["Genetic_Composite", "Genetic_Multivariate"],
                "methodology": "é—ä¼ ç®—æ³•ä¼˜åŒ–å› å­è¡¨è¾¾å¼"
            }
        },
        
        "key_insights": {
            "best_performing_market": max(portfolio_summary.keys(), 
                                        key=lambda m: max([metrics['sharpe_ratio'] for metrics in portfolio_summary[m].values()])),
            "most_stable_factors": [],
            "highest_sharpe_method": "hrp",
            "risk_return_tradeoff": "HRPæ–¹æ³•åœ¨æ‰€æœ‰å¸‚åœºéƒ½è¡¨ç°å‡ºæœ€é«˜çš„å¤æ™®æ¯”ç‡",
            "factor_diversity": "äº”ä¸ªä¸åŒçš„å› å­ç”Ÿæˆæ–¹æ³•æä¾›äº†è‰¯å¥½çš„å› å­å¤šæ ·æ€§"
        }
    }
    
    # æ‰¾å‡ºæœ€ç¨³å®šçš„å› å­
    all_factors = {}
    for market in ["a_share", "crypto", "us"]:
        for factor, quality in comprehensive_data["factor_analysis"][market]["factor_quality"].items():
            all_factors[f"{market}_{factor}"] = quality["overall_quality"]
    
    comprehensive_data["key_insights"]["most_stable_factors"] = sorted(
        all_factors.items(), key=lambda x: x[1], reverse=True
    )[:5]
    
    return comprehensive_data


def main():
    """ä¸»å‡½æ•°"""
    print("Creating comprehensive JSON input for Report Agent...")
    
    try:
        # åˆ›å»ºç»¼åˆæ•°æ®
        comprehensive_data = create_comprehensive_json()
        
        # ä¿å­˜JSONæ–‡ä»¶
        output_path = Path("report_agent") / "input_data.json"
        output_path.parent.mkdir(exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Comprehensive JSON file created: {output_path}")
        print(f"ğŸ“Š Total data points: {comprehensive_data['metadata']['total_factors']} factors across {comprehensive_data['metadata']['total_markets']} markets")
        print(f"ğŸ¯ Optimization methods: {', '.join(comprehensive_data['metadata']['optimization_methods'])}")
        
        # æ˜¾ç¤ºå…³é”®ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“ˆ Key Statistics:")
        for market in ["a_share", "crypto", "us"]:
            market_data = comprehensive_data["factor_analysis"][market]
            print(f"  {market.upper()}: {market_data['total_factors']} factors, {len(market_data['high_quality_factors'])} high-quality")
        
        print(f"\nğŸ† Best performing market: {comprehensive_data['key_insights']['best_performing_market'].upper()}")
        print(f"ğŸ“Š Most stable factors: {[f[0] for f in comprehensive_data['key_insights']['most_stable_factors'][:3]]}")
        
    except Exception as e:
        print(f"âŒ Error creating JSON file: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()