#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è„šæœ¬ï¼šæ£€æŸ¥å› å­è¯„ä¼°é—®é¢˜
ç”¨äºè¯Šæ–­ä¸ºä»€ä¹ˆæ‰€æœ‰å› å­çš„ICå’ŒSharpeå€¼éƒ½ä¸º0
"""

import os
import sys
import pandas as pd
import numpy as np
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('test_evaluation')

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½å’ŒåŸºæœ¬ç»Ÿè®¡"""
    logger.info("ğŸ” å¼€å§‹æµ‹è¯•æ•°æ®åŠ è½½")
    
    # å°è¯•ç›´æ¥åŠ è½½æ•°æ®å¹¶æ£€æŸ¥
    data_path = os.path.join(os.path.dirname(__file__), 'data/a_share')
    if not os.path.exists(data_path):
        # ä½¿ç”¨é»˜è®¤è·¯å¾„
        data_path = 'data/a_share'
    
    logger.info(f"ğŸ“‚ æµ‹è¯•æ•°æ®è·¯å¾„: {data_path}")
    
    # å°è¯•è¯»å–ä¸€äº›CSVæ–‡ä»¶
    import glob
    csv_files = glob.glob(os.path.join(data_path, "*.csv"))
    logger.info(f"ğŸ“„ æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    
    if csv_files:
        # è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œæµ‹è¯•
        test_file = csv_files[0]
        logger.info(f"ğŸ” æµ‹è¯•æ–‡ä»¶: {test_file}")
        
        try:
            df = pd.read_csv(test_file)
            logger.info(f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶ï¼Œå½¢çŠ¶: {df.shape}")
            logger.info(f"ğŸ“‹ æ•°æ®åˆ—: {list(df.columns)}")
            logger.info(f"ğŸ“Š æ•°æ®æ‘˜è¦:\n{df.describe()}")
            
            # æ£€æŸ¥æ—¥æœŸåˆ—
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])
                logger.info(f"ğŸ“… æ—¥æœŸèŒƒå›´: {df['date'].min()} åˆ° {df['date'].max()}")
            
            # æ£€æŸ¥ä»·æ ¼åˆ—
            for col in ['open', 'high', 'low', 'close']:
                if col in df.columns:
                    logger.info(f"ğŸ“ˆ {col} åˆ—ç»Ÿè®¡: å‡å€¼={df[col].mean():.2f}, æ ‡å‡†å·®={df[col].std():.2f}")
                    # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
                    if df[col].std() == 0:
                        logger.warning(f"âš ï¸  {col} åˆ—æ²¡æœ‰å˜åŒ–ï¼Œæ‰€æœ‰å€¼ç›¸åŒ")
            
            # è®¡ç®—æ”¶ç›Šç‡
            if 'close' in df.columns:
                df['returns'] = df['close'].pct_change()
                logger.info(f"ğŸ“Š æ”¶ç›Šç‡ç»Ÿè®¡: å‡å€¼={df['returns'].mean():.6f}, æ ‡å‡†å·®={df['returns'].std():.6f}")
                logger.info(f"ğŸ“Š éé›¶æ”¶ç›Šç‡æ•°é‡: {(df['returns'].fillna(0) != 0).sum()}")
                
                # å¦‚æœæ”¶ç›Šç‡å…¨ä¸º0ï¼Œè®°å½•è­¦å‘Š
                if (df['returns'].fillna(0) == 0).all():
                    logger.warning("âŒ æ‰€æœ‰æ”¶ç›Šç‡éƒ½ä¸º0ï¼Œè¿™ä¼šå¯¼è‡´ICå’ŒSharpeå€¼ä¸º0")
            
        except Exception as e:
            logger.error(f"âŒ è¯»å–æµ‹è¯•æ–‡ä»¶å¤±è´¥: {e}")
    else:
        logger.warning(f"âš ï¸  åœ¨è·¯å¾„ {data_path} ä¸‹æœªæ‰¾åˆ°CSVæ–‡ä»¶")

def test_factor_calculation():
    """æµ‹è¯•å› å­è®¡ç®—é€»è¾‘"""
    logger.info("ğŸ” å¼€å§‹æµ‹è¯•å› å­è®¡ç®—é€»è¾‘")
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
    dates = pd.date_range(start='2024-01-01', periods=20)
    stocks = ['A', 'B', 'C', 'D', 'E']
    
    # åˆ›å»ºä»·æ ¼æ•°æ®
    np.random.seed(42)
    price_data = pd.DataFrame(
        np.random.rand(len(dates), len(stocks)),
        index=dates,
        columns=stocks
    )
    
    logger.info(f"ğŸ“Š åˆ›å»ºæµ‹è¯•ä»·æ ¼æ•°æ®ï¼Œå½¢çŠ¶: {price_data.shape}")
    logger.info(f"ğŸ“Š ä»·æ ¼æ•°æ®ç¤ºä¾‹:\n{price_data.head()}")
    
    # åˆ›å»ºæ”¶ç›Šç‡æ•°æ®
    returns_data = price_data.pct_change().fillna(0)
    logger.info(f"ğŸ“Š æ”¶ç›Šç‡æ•°æ®ç¤ºä¾‹:\n{returns_data.head()}")
    
    # åˆ›å»ºä¸€ä¸ªç®€å•å› å­ (ä»·æ ¼åŠ¨é‡)
    factor_data = price_data.pct_change(5)
    logger.info(f"ğŸ“Š å› å­æ•°æ®ç¤ºä¾‹:\n{factor_data.head()}")
    
    # æµ‹è¯•ICè®¡ç®—
    daily_ics = []
    for date in dates[6:]:  # è·³è¿‡å‰5å¤©çš„NAå€¼
        if date in factor_data.index and date in returns_data.index:
            # è·å–å½“æ—¥çš„å› å­å€¼å’Œæ¬¡æ—¥æ”¶ç›Šç‡
            factor_values = factor_data.loc[date].dropna()
            ret_values = returns_data.shift(-1).loc[date].dropna()
            
            # å¯¹é½è‚¡ç¥¨
            common_stocks = factor_values.index.intersection(ret_values.index)
            if len(common_stocks) >= 2:
                factor_values = factor_values.loc[common_stocks]
                ret_values = ret_values.loc[common_stocks]
                
                # è®¡ç®—Spearmanç›¸å…³ç³»æ•°
                if factor_values.std() > 0 and ret_values.std() > 0:
                    ic = factor_values.rank().corr(ret_values.rank(), method='spearman')
                    daily_ics.append(ic)
                    logger.info(f"ğŸ“… æ—¥æœŸ {date}: IC = {ic:.4f}")
    
    if daily_ics:
        avg_ic = np.mean(daily_ics)
        logger.info(f"ğŸ“Š å¹³å‡IC: {avg_ic:.4f}")
    else:
        logger.warning("âš ï¸  æ— æ³•è®¡ç®—ICï¼Œæ•°æ®ä¸è¶³æˆ–æœ‰é—®é¢˜")

def test_config_file():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    logger.info("ğŸ” å¼€å§‹æµ‹è¯•é…ç½®æ–‡ä»¶")
    
    config_path = 'standardized_eval_config.json'
    if os.path.exists(config_path):
        try:
            import json
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶ï¼Œå†…å®¹: {config}")
            
            # æ£€æŸ¥mock-modeè®¾ç½®
            if 'mock-mode' in config and config['mock-mode'] is True:
                logger.warning("âš ï¸  å‘ç°å…³é”®é—®é¢˜: mock-mode è®¾ç½®ä¸º Trueï¼Œè¿™ä¼šå¯¼è‡´ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æˆ–é»˜è®¤å€¼")
                logger.warning("âš ï¸  è¿™å¾ˆå¯èƒ½æ˜¯æ‰€æœ‰å› å­ICå’ŒSharpeå€¼éƒ½ä¸º0çš„åŸå› ")
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    else:
        logger.warning(f"âš ï¸  é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
        # å°è¯•åˆ›å»ºé…ç½®æ–‡ä»¶ï¼Œå…³é—­mockæ¨¡å¼
        try:
            default_config = {
                'data-path': 'c:/Users/Administrator/Desktop/alpha-master/data/a_share/csi500data',
                'factors-file': 'c:/Users/Administrator/Desktop/alpha-master/a_factor_generate/all_factors_expressions.json',
                'complementary-count': 3,
                'llm-provider': 'dashscope',
                'llm-model': 'qwen-turbo',
                'llm-api-key': 'sk-429ed6e6cfa347ddb5005e178edd3f90',
                'run-standardized-eval': True,
                'mock-mode': False  # å…³é—­mockæ¨¡å¼
            }
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, indent=2)
            logger.info(f"âœ… åˆ›å»ºäº†æ–°çš„é…ç½®æ–‡ä»¶ï¼Œå…³é—­äº†mockæ¨¡å¼: {config_path}")
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºé…ç½®æ–‡ä»¶å¤±è´¥: {e}")

def test_factors_file():
    """æµ‹è¯•å› å­æ–‡ä»¶åŠ è½½"""
    logger.info("ğŸ” å¼€å§‹æµ‹è¯•å› å­æ–‡ä»¶")
    
    factors_path = 'c:/Users/Administrator/Desktop/alpha-master/a_factor_generate/all_factors_expressions.json'
    if os.path.exists(factors_path):
        try:
            import json
            with open(factors_path, 'r', encoding='utf-8') as f:
                factors = json.load(f)
            logger.info(f"âœ… æˆåŠŸåŠ è½½å› å­æ–‡ä»¶ï¼Œå…± {len(factors)} ä¸ªå› å­")
            # æ˜¾ç¤ºå‰2ä¸ªå› å­ä½œä¸ºç¤ºä¾‹
            if isinstance(factors, list) and factors:
                for i, factor in enumerate(factors[:2]):
                    logger.info(f"ğŸ“Š å› å­ {i+1}: {factor}")
            else:
                logger.warning(f"âš ï¸  å› å­æ–‡ä»¶æ ¼å¼å¼‚å¸¸ï¼Œä¸æ˜¯é¢„æœŸçš„åˆ—è¡¨æ ¼å¼: {type(factors)}")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å› å­æ–‡ä»¶å¤±è´¥: {e}")
    else:
        logger.warning(f"âš ï¸  å› å­æ–‡ä»¶ {factors_path} ä¸å­˜åœ¨")

def test_mock_mode_impact():
    """æµ‹è¯•mockæ¨¡å¼çš„å½±å“"""
    logger.info("ğŸ” å¼€å§‹æµ‹è¯•mockæ¨¡å¼å½±å“")
    
    # åˆ†æmockæ¨¡å¼å¯¹è¯„ä¼°ç»“æœçš„å½±å“
    logger.info("ğŸ“Š mockæ¨¡å¼é€šå¸¸ä¼šå¯¼è‡´:")
    logger.info("   1. ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è€Œä¸æ˜¯çœŸå®æ•°æ®")
    logger.info("   2. è¿”å›é»˜è®¤è¯„ä¼°å€¼ï¼ˆå¦‚IC=0.0000ï¼ŒSharpe=0.0000ï¼‰")
    logger.info("   3. è·³è¿‡å®é™…çš„å› å­è®¡ç®—å’Œå›æµ‹")
    logger.info("ğŸ“‹ å»ºè®®æ“ä½œ:")
    logger.info("   1. å…³é—­mock-modeï¼Œè®¾ç½®ä¸ºFalse")
    logger.info("   2. ç¡®ä¿æ•°æ®è·¯å¾„æ­£ç¡®ä¸”åŒ…å«æœ‰æ•ˆæ•°æ®")
    logger.info("   3. é‡æ–°è¿è¡Œè¯„ä¼°æµç¨‹")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å› å­è¯„ä¼°é—®é¢˜è¯Šæ–­")
    
    # æµ‹è¯•é…ç½®æ–‡ä»¶ï¼ˆä¼˜å…ˆæ£€æŸ¥ï¼Œå› ä¸ºmock-modeæ˜¯å…³é”®é—®é¢˜ï¼‰
    test_config_file()
    
    # æµ‹è¯•mockæ¨¡å¼å½±å“åˆ†æ
    test_mock_mode_impact()
    
    # æµ‹è¯•æ•°æ®åŠ è½½
    test_data_loading()
    
    # æµ‹è¯•å› å­è®¡ç®—é€»è¾‘
    test_factor_calculation()
    
    # æµ‹è¯•å› å­æ–‡ä»¶
    test_factors_file()
    
    logger.info("ğŸ‰ è¯Šæ–­å®Œæˆ")
    logger.info("ğŸ“‹ æ€»ç»“: ICå’ŒSharpeå€¼ä¸º0.0000çš„æœ€å¯èƒ½åŸå› æ˜¯mock-mode=True")
    logger.info("ğŸ“‹ è§£å†³æ–¹æ¡ˆ: ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œå°†mock-modeè®¾ç½®ä¸ºFalseåé‡æ–°è¿è¡Œ")

if __name__ == "__main__":
    main()