# -*- coding: utf-8 -*-
"""
å› å­æ± ç®¡ç†å™¨
ç®¡ç†æœ‰æ•ˆå› å­æ± (effective_pool)å’ŒåºŸå¼ƒå› å­æ± (discarded_pool)
"""

import pandas as pd
import numpy as np
import os
import json
import pickle
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('dual_chain.factor_pool')

class FactorPool:
    """
    å› å­æ± ç®¡ç†å™¨
    è´Ÿè´£æœ‰æ•ˆå› å­æ± å’ŒåºŸå¼ƒå› å­æ± çš„å­˜å‚¨ã€è¯»å–å’Œæ›´æ–°
    """
    
    def __init__(self, pool_dir: str = "dual_chain/pools", initial_factors_file: str = None):
        """
        åˆå§‹åŒ–å› å­æ± ç®¡ç†å™¨
        
        Args:
            pool_dir: å› å­æ± å­˜å‚¨ç›®å½•
            initial_factors_file: åˆå§‹å› å­æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.pool_dir = pool_dir
        self.effective_pool_path = os.path.join(pool_dir, "effective_pool")
        self.discarded_pool_path = os.path.join(pool_dir, "discarded_pool")
        self.metadata_path = os.path.join(pool_dir, "metadata.json")
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        os.makedirs(self.effective_pool_path, exist_ok=True)
        os.makedirs(self.discarded_pool_path, exist_ok=True)
        
        # åˆå§‹åŒ–å…ƒæ•°æ®
        self._init_metadata()
        
        # å¦‚æœæä¾›äº†åˆå§‹å› å­æ–‡ä»¶ï¼ŒåŠ è½½åˆå§‹å› å­
        if initial_factors_file and os.path.exists(initial_factors_file):
            logger.info(f"ğŸ“¥ å¼€å§‹ä»åˆå§‹å› å­æ–‡ä»¶åŠ è½½å› å­: {initial_factors_file}")
            self.load_initial_factors(initial_factors_file)
        
        logger.info(f"âœ… å› å­æ± ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæœ‰æ•ˆæ± è·¯å¾„: {self.effective_pool_path}")
        logger.info(f"âœ… å› å­æ± ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼ŒåºŸå¼ƒæ± è·¯å¾„: {self.discarded_pool_path}")
    
    def _init_metadata(self):
        """
        åˆå§‹åŒ–å…ƒæ•°æ®
        """
        if not os.path.exists(self.metadata_path):
            metadata = {
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat(),
                "effective_factors_count": 0,
                "discarded_factors_count": 0,
                "total_iterations": 0
            }
            with open(self.metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    def update_metadata(self, key: str, value: Any):
        """
        æ›´æ–°å…ƒæ•°æ®
        
        Args:
            key: å…ƒæ•°æ®é”®
            value: å…ƒæ•°æ®å€¼
        """
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        metadata[key] = value
        metadata["last_updated"] = datetime.now().isoformat()
        
        with open(self.metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    def add_effective_factor(self, factor_name: str, factor_data: pd.DataFrame, 
                           factor_expression: str, evaluation_metrics: Dict[str, float]):
        """
        æ·»åŠ æœ‰æ•ˆå› å­åˆ°æœ‰æ•ˆå› å­æ± 
        
        Args:
            factor_name: å› å­åç§°
            factor_data: å› å­æ•°æ®
            factor_expression: å› å­è¡¨è¾¾å¼/æè¿°
            evaluation_metrics: è¯„ä¼°æŒ‡æ ‡
        """
        # ä¿å­˜å› å­æ•°æ®
        data_path = os.path.join(self.effective_pool_path, f"{factor_name}_data.pkl")
        factor_data.to_pickle(data_path)
        
        # ä¿å­˜å› å­å…ƒä¿¡æ¯
        metadata = {
            "name": factor_name,
            "expression": factor_expression,
            "evaluation_metrics": evaluation_metrics,
            "added_at": datetime.now().isoformat()
        }
        
        meta_path = os.path.join(self.effective_pool_path, f"{factor_name}_metadata.json")
        with open(meta_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # æ›´æ–°æ€»è®¡æ•°
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        metadata["effective_factors_count"] = len(self.get_effective_factors_list())
        self.update_metadata("effective_factors_count", metadata["effective_factors_count"])
        
        logger.info(f"âœ… å› å­æ·»åŠ åˆ°æœ‰æ•ˆæ± : {factor_name}, IC: {evaluation_metrics.get('ic', 'N/A'):.4f}")
    
    def add_discarded_factor(self, factor_name: str, factor_data: pd.DataFrame, 
                           factor_expression: str, evaluation_metrics: Dict[str, float],
                           reason: str):
        """
        æ·»åŠ åºŸå¼ƒå› å­åˆ°åºŸå¼ƒå› å­æ± 
        
        Args:
            factor_name: å› å­åç§°
            factor_data: å› å­æ•°æ®
            factor_expression: å› å­è¡¨è¾¾å¼/æè¿°
            evaluation_metrics: è¯„ä¼°æŒ‡æ ‡
            reason: åºŸå¼ƒåŸå› 
        """
        # ä¿å­˜å› å­æ•°æ®
        data_path = os.path.join(self.discarded_pool_path, f"{factor_name}_data.pkl")
        factor_data.to_pickle(data_path)
        
        # ä¿å­˜å› å­å…ƒä¿¡æ¯
        metadata = {
            "name": factor_name,
            "expression": factor_expression,
            "evaluation_metrics": evaluation_metrics,
            "discarded_at": datetime.now().isoformat(),
            "reason": reason
        }
        
        meta_path = os.path.join(self.discarded_pool_path, f"{factor_name}_metadata.json")
        with open(meta_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        # æ›´æ–°æ€»è®¡æ•°
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        metadata["discarded_factors_count"] = len(self.get_discarded_factors_list())
        self.update_metadata("discarded_factors_count", metadata["discarded_factors_count"])
        
        logger.info(f"âŒ å› å­æ·»åŠ åˆ°åºŸå¼ƒæ± : {factor_name}, åŸå› : {reason}")
    
    def get_effective_factors_list(self) -> List[str]:
        """
        è·å–æœ‰æ•ˆå› å­åˆ—è¡¨
        
        Returns:
            æœ‰æ•ˆå› å­åç§°åˆ—è¡¨
        """
        factors = []
        for file in os.listdir(self.effective_pool_path):
            if file.endswith("_metadata.json"):
                factor_name = file.replace("_metadata.json", "")
                factors.append(factor_name)
        return factors
    
    def get_discarded_factors_list(self) -> List[str]:
        """
        è·å–åºŸå¼ƒå› å­åˆ—è¡¨
        
        Returns:
            åºŸå¼ƒå› å­åç§°åˆ—è¡¨
        """
        factors = []
        for file in os.listdir(self.discarded_pool_path):
            if file.endswith("_metadata.json"):
                factor_name = file.replace("_metadata.json", "")
                factors.append(factor_name)
        return factors
    
    def get_factor_metadata(self, factor_name: str, is_effective: bool = True) -> Dict[str, Any]:
        """
        è·å–å› å­å…ƒä¿¡æ¯
        
        Args:
            factor_name: å› å­åç§°
            is_effective: æ˜¯å¦ä¸ºæœ‰æ•ˆå› å­
            
        Returns:
            å› å­å…ƒä¿¡æ¯
        """
        pool_path = self.effective_pool_path if is_effective else self.discarded_pool_path
        meta_path = os.path.join(pool_path, f"{factor_name}_metadata.json")
        
        if not os.path.exists(meta_path):
            raise FileNotFoundError(f"å› å­å…ƒä¿¡æ¯ä¸å­˜åœ¨: {factor_name}")
        
        with open(meta_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def load_initial_factors(self, factors_file: str) -> List[Dict[str, Any]]:
        """
        ä»JSONæ–‡ä»¶åŠ è½½åˆå§‹å› å­
        
        Args:
            factors_file: å› å­æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŠ è½½çš„å› å­åˆ—è¡¨
        """
        try:
            with open(factors_file, 'r', encoding='utf-8') as f:
                factors_data = json.load(f)
            
            loaded_factors = []
            # éå†æ‰€æœ‰æ¥æºçš„å› å­
            for source, factors in factors_data.items():
                logger.info(f"ğŸ” å¤„ç†æ¥æº: {source}ï¼ŒåŒ…å« {len(factors)} ä¸ªå› å­")
                for factor in factors:
                    # æå–å› å­ä¿¡æ¯
                    factor_info = {
                        "name": factor.get("name", f"{source}_factor_{len(loaded_factors)+1}"),
                        "expression": factor.get("expression", ""),
                        "description": factor.get("description", ""),
                        "source": source,
                        "parameters": factor.get("parameters", {})
                    }
                    loaded_factors.append(factor_info)
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(loaded_factors)} ä¸ªåˆå§‹å› å­")
            return loaded_factors
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½åˆå§‹å› å­å¤±è´¥: {e}")
            return []
    
    def get_pool_statistics(self) -> Dict[str, Any]:
        """
        è·å–å› å­æ± ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            å› å­æ± ç»Ÿè®¡ä¿¡æ¯
        """
        effective_factors = self.get_effective_factors_list()
        discarded_factors = self.get_discarded_factors_list()
        
        stats = {
            "effective_factors_count": len(effective_factors),
            "discarded_factors_count": len(discarded_factors),
            "total_factors": len(effective_factors) + len(discarded_factors)
        }
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        effective_ics = []
        effective_ic_irs = []
        effective_sharpes = []
        
        for factor_name in effective_factors:
            try:
                metadata = self.get_factor_metadata(factor_name)
                metrics = metadata.get("evaluation_metrics", {})
                if "ic" in metrics:
                    effective_ics.append(metrics["ic"])
                if "ic_ir" in metrics:
                    effective_ic_irs.append(metrics["ic_ir"])
                if "sharpe" in metrics:
                    effective_sharpes.append(metrics["sharpe"])
            except Exception as e:
                logger.error(f"âŒ è·å–å› å­ {factor_name} ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        
        if effective_ics:
            stats["avg_effective_ic"] = np.mean(effective_ics)
            stats["avg_effective_ic_ir"] = np.mean(effective_ic_irs) if effective_ic_irs else 0
            stats["avg_effective_sharpe"] = np.mean(effective_sharpes) if effective_sharpes else 0
        
        discarded_ics = []
        discarded_sharpes = []
        
        for factor_name in discarded_factors:
            try:
                metadata = self.get_factor_metadata(factor_name, is_effective=False)
                metrics = metadata.get("evaluation_metrics", {})
                if "ic" in metrics:
                    discarded_ics.append(metrics["ic"])
                if "sharpe" in metrics:
                    discarded_sharpes.append(metrics["sharpe"])
            except Exception as e:
                logger.error(f"âŒ è·å–åºŸå¼ƒå› å­ {factor_name} ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        
        if discarded_ics:
            stats["avg_discarded_ic"] = np.mean(discarded_ics)
            stats["avg_discarded_sharpe"] = np.mean(discarded_sharpes) if discarded_sharpes else 0
        
        return stats
    
    def get_factor_data(self, factor_name: str, is_effective: bool = True) -> pd.DataFrame:
        """
        è·å–å› å­æ•°æ®
        
        Args:
            factor_name: å› å­åç§°
            is_effective: æ˜¯å¦ä¸ºæœ‰æ•ˆå› å­
            
        Returns:
            å› å­æ•°æ®
        """
        pool_path = self.effective_pool_path if is_effective else self.discarded_pool_path
        data_path = os.path.join(pool_path, f"{factor_name}_data.pkl")
        
        if not os.path.exists(data_path):
            raise FileNotFoundError(f"å› å­æ•°æ®ä¸å­˜åœ¨: {factor_name}")
        
        return pd.read_pickle(data_path)
    
    def get_reference_factors(self, top_n: int = 5) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """
        è·å–å‚è€ƒå› å­ï¼Œç”¨äºæŒ‡å¯¼æ–°å› å­ç”Ÿæˆ
        
        Args:
            top_n: è¿”å›å‰Nä¸ªå› å­
            
        Returns:
            (æœ‰æ•ˆå› å­åˆ—è¡¨, åºŸå¼ƒå› å­åˆ—è¡¨)
        """
        # è·å–æœ‰æ•ˆå› å­ï¼ŒæŒ‰ICæ’åº
        effective_factors = []
        for factor_name in self.get_effective_factors_list():
            metadata = self.get_factor_metadata(factor_name, is_effective=True)
            effective_factors.append(metadata)
        
        # æŒ‰ICé™åºæ’åº
        effective_factors.sort(key=lambda x: x["evaluation_metrics"].get("ic", 0), reverse=True)
        
        # è·å–åºŸå¼ƒå› å­ï¼ŒæŒ‰ICå‡åºæ’åºï¼ˆæœ€å·®çš„å› å­ï¼‰
        discarded_factors = []
        for factor_name in self.get_discarded_factors_list():
            metadata = self.get_factor_metadata(factor_name, is_effective=False)
            discarded_factors.append(metadata)
        
        # æŒ‰ICå‡åºæ’åº
        discarded_factors.sort(key=lambda x: x["evaluation_metrics"].get("ic", 0), reverse=False)
        
        return effective_factors[:top_n], discarded_factors[:top_n]
    
    def remove_factor(self, factor_name: str, is_effective: bool = True):
        """
        ä»å› å­æ± ä¸­ç§»é™¤å› å­
        
        Args:
            factor_name: å› å­åç§°
            is_effective: æ˜¯å¦ä¸ºæœ‰æ•ˆå› å­
        """
        pool_path = self.effective_pool_path if is_effective else self.discarded_pool_path
        
        # åˆ é™¤æ•°æ®æ–‡ä»¶
        data_path = os.path.join(pool_path, f"{factor_name}_data.pkl")
        if os.path.exists(data_path):
            os.remove(data_path)
        
        # åˆ é™¤å…ƒä¿¡æ¯æ–‡ä»¶
        meta_path = os.path.join(pool_path, f"{factor_name}_metadata.json")
        if os.path.exists(meta_path):
            os.remove(meta_path)
        
        # æ›´æ–°è®¡æ•°
        if is_effective:
            self.update_metadata("effective_factors_count", len(self.get_effective_factors_list()))
        else:
            self.update_metadata("discarded_factors_count", len(self.get_discarded_factors_list()))
        
        logger.info(f"ğŸ—‘ï¸  å› å­å·²ä»{'æœ‰æ•ˆæ± ' if is_effective else 'åºŸå¼ƒæ± '}ç§»é™¤: {factor_name}")
    
    def get_pool_statistics(self) -> Dict[str, Any]:
        """
        è·å–å› å­æ± ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # è®¡ç®—æœ‰æ•ˆå› å­çš„å¹³å‡IC
        effective_factors = self.get_effective_factors_list()
        avg_effective_ic = 0
        if effective_factors:
            ics = []
            for factor_name in effective_factors:
                meta = self.get_factor_metadata(factor_name, is_effective=True)
                ics.append(meta["evaluation_metrics"].get("ic", 0))
            avg_effective_ic = np.mean(ics)
        
        # è®¡ç®—åºŸå¼ƒå› å­çš„å¹³å‡IC
        discarded_factors = self.get_discarded_factors_list()
        avg_discarded_ic = 0
        if discarded_factors:
            ics = []
            for factor_name in discarded_factors:
                meta = self.get_factor_metadata(factor_name, is_effective=False)
                ics.append(meta["evaluation_metrics"].get("ic", 0))
            avg_discarded_ic = np.mean(ics)
        
        statistics = {
            "effective_factors_count": metadata["effective_factors_count"],
            "discarded_factors_count": metadata["discarded_factors_count"],
            "total_iterations": metadata["total_iterations"],
            "created_at": metadata["created_at"],
            "last_updated": metadata["last_updated"],
            "avg_effective_ic": avg_effective_ic,
            "avg_discarded_ic": avg_discarded_ic
        }
        
        return statistics